import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
import cv2
import time
import sys
import os
import urllib.request

import config


# ==========================================
# æ ¸å¿ƒå¯¼å…¥åŒº
# ==========================================


# ==========================================
# çº¯æ‰‹åŠ¨ç»˜åˆ¶å·¥å…· (ä¸ä¾èµ– mp.solutions)
# ==========================================
class ManualDrawer:
    """
    è‡ªå·±å®ç°çš„ç»˜å›¾ç±»ï¼Œå®Œå…¨ç»•è¿‡ mediapipe.solutions.drawing_utils
    é˜²æ­¢å›  protobuf ç‰ˆæœ¬å†²çªå¯¼è‡´çš„ AttributeError
    """
    # èº«ä½“è¿æ¥å…³ç³» (MediaPipe æ ‡å‡†æ‹“æ‰‘)
    POSE_CONNECTIONS = [
        (11, 12), (11, 13), (13, 15), (12, 14), (14, 16), (11, 23), (12, 24),
        (23, 24), (23, 25), (24, 26), (25, 27), (26, 28), (27, 29), (28, 30),
        (29, 31), (30, 32), (27, 31), (28, 32)
    ]

    @staticmethod
    def draw(image, detection_result):
        # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°äººï¼Œç›´æ¥è¿”å›
        if not detection_result.pose_landmarks:
            return image

        annotated_image = image.copy()
        h, w, _ = image.shape

        # éå†æ¯ä¸€ä¸ªæ£€æµ‹åˆ°çš„äºº
        for pose_landmarks in detection_result.pose_landmarks:
            # 1. å…ˆç”»è¿æ¥çº¿ (éª¨éª¼)
            for start_idx, end_idx in ManualDrawer.POSE_CONNECTIONS:
                # è·å–å½’ä¸€åŒ–åæ ‡
                start_pt = pose_landmarks[start_idx]
                end_pt = pose_landmarks[end_idx]

                # è½¬æ¢ä¸ºåƒç´ åæ ‡
                px_start = (int(start_pt.x * w), int(start_pt.y * h))
                px_end = (int(end_pt.x * w), int(end_pt.y * h))

                # ç®€å•çš„å¯è§æ€§è¿‡æ»¤
                if start_pt.visibility > 0.5 and end_pt.visibility > 0.5:
                    cv2.line(annotated_image, px_start, px_end, (255, 255, 255), 2)

            # 2. å†ç”»å…³é”®ç‚¹ (å…³èŠ‚)
            for idx, landmark in enumerate(pose_landmarks):
                if landmark.visibility > 0.5:  # åªç”»å¯è§åº¦é«˜çš„ç‚¹
                    cx, cy = int(landmark.x * w), int(landmark.y * h)
                    # ç”»å¤–åœˆ
                    cv2.circle(annotated_image, (cx, cy), 4, (0, 0, 255), -1)
                    # ç”»å†…èŠ¯
                    cv2.circle(annotated_image, (cx, cy), 2, (255, 255, 255), -1)

        return annotated_image


# ==========================================
# ä¸»æ£€æµ‹ç±»
# ==========================================
class PoseCheck:
    def __init__(self, model_name=config.MP_PATH):
        self.model_name = model_name
        self.ensure_model_exists()

        # åŠ è½½æ¨¡å‹äºŒè¿›åˆ¶æ•°æ® (æ¯”è·¯å¾„åŠ è½½æ›´ç¨³å®š)
        with open(self.model_name, 'rb') as f:
            model_bytes = f.read()

        base_options = python.BaseOptions(model_asset_buffer=model_bytes)
        options = vision.PoseLandmarkerOptions(
            base_options=base_options,
            running_mode=vision.RunningMode.IMAGE,
            # è®¾ä¸º True å¯ä»¥è¾“å‡ºåˆ†å‰²æ©ç ï¼Œå¦‚æœä¸éœ€å¯è®¾ False åŠ é€Ÿ
            output_segmentation_masks=False
        )
        self.detector = vision.PoseLandmarker.create_from_options(options)
        print("âœ… æ£€æµ‹å™¨åˆå§‹åŒ–æˆåŠŸï¼")

    def ensure_model_exists(self):
        """å¦‚æœæœ¬åœ°æ²¡æœ‰æ¨¡å‹æ–‡ä»¶ï¼Œè‡ªåŠ¨å» Google å®˜ç½‘ä¸‹è½½"""
        if not os.path.exists(self.model_name):
            print(f"âš ï¸ æœ¬åœ°æœªæ‰¾åˆ° {self.model_name}ï¼Œæ­£åœ¨è‡ªåŠ¨ä¸‹è½½ (çº¦ 30MB)...")
            url = "https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_heavy/float16/1/pose_landmarker_heavy.task"
            try:
                urllib.request.urlretrieve(url, self.model_name)
                print("âœ… ä¸‹è½½å®Œæˆï¼")
            except Exception as e:
                print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
                print("è¯·æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶å¹¶æ”¾åˆ°è„šæœ¬åŒçº§ç›®å½•ã€‚")
                sys.exit(1)
        print(f"æœ¬åœ°æ‰¾åˆ° {self.model_name}")

    def check(self, cv2_frame):
        # è½¬æ¢é¢œè‰²ç©ºé—´ BGR -> RGB
        rgb_frame = cv2.cvtColor(cv2_frame, cv2.COLOR_BGR2RGB)
        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)

        start_time = time.perf_counter()
        result = self.detector.detect(mp_image)
        latency = time.perf_counter() - start_time

        return result, latency

    def close(self):
        if hasattr(self, 'detector'):
            self.detector.close()


# ==========================================
# ç¨‹åºå…¥å£
# ==========================================
if __name__ == "__main__":
    # åˆå§‹åŒ–æ£€æµ‹å™¨
    checker = PoseCheck()

    print("\nğŸš€ å¼€å§‹è¿è¡Œ... æŒ‰ 'ESC' é€€å‡º")

    try:
        frame =cv2.imread("./run.png")
        detection_result, latency = checker.check(frame)
        # 2. ç»˜åˆ¶ (ä½¿ç”¨è‡ªå®šä¹‰çš„ ManualDrawerï¼Œä¸ä¾èµ–å®˜æ–¹åº“)
        annotated_frame = ManualDrawer.draw(frame, detection_result)
        cv2.imshow('MediaPipe Stable Pose', annotated_frame)

        if cv2.waitKey(0) & 0xFF == 27:
            pass

    except Exception as e:
        print(f"âŒ è¿è¡Œä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    finally:
        checker.close()
        cv2.destroyAllWindows()